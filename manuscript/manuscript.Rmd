---
title: The dynamics of risk perception in a Mediterranean agroecosystem
subtitle: 
titlerunning: The dynamics of risk and risk perception in a Mediterranean agroecosystem
authorrunning: Gauthier

authors: 
- name: Nicolas Gauthier
  address: Laboratory of Tree-Ring Research & School of Geography and Development, University of Arizona
  email: ngauthier@arizona.edu
  

keywords:
- belief-based agents
- drought risk
- crop diversification
- rapid climate change

abstract: |
  Small-scale agriculturalists in the Mediterranean Basin rely on multiple strategies including diversification, intensification, and storage to maintain a stable food supply in the face of environmental uncertainty. Each of these strategies requires farmers to make specific resource allocation decisions in response to environmental risks and is thus sensitive to variability in both the spatiotemporal pattern of risk and the ability of farmers to perceive that pattern. In this chapter, I present an agent-based model of a Mediterranean agroecosystem. By driving the model with realistic environmental dynamics derived from simulations of mid-Holocene Mediterranean climate, and by allowing the psychology of risk perception to vary among individual farmers, I explore the hidden vulnerabilities of traditional risk-management strategies to periods of rapid climate change. I show that even when farmers are able to manage risk “optimally” in light of past experience, unanticipated changes in the spatiotemporal pattern of rainfall can still lead to major food shortfalls.

bibliography: bibliography.bib
bibstyle: Formato_bibliografia_Springer
# bibstyle options spbasic(default), spphys, spmpsci
output:
  bookdown::pdf_book:
    base_format: rticles::springer_article
    number_sections: yes
header-includes:
- \usepackage{float}
- \floatplacement{figure}{tb}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, fig.width = 5, fig.asp = 0.618)
library(raster)
library(ncdf4)
library(tidyverse)
library(patchwork)
```


# Introduction {#intro}

The distinctive climate and ecology of the Mediterranean basin afforded both challenges and opportunities to the earliest farming communities. Here, water is the primary limiting resource for traditional agroecosystems. Agricultural droughts -- where growing season precipitation is low enough to cause crop failures, are a constant threat. Precipitation is highly variable in space and time and droughts are difficult to predict with any certainty. How were Neolithic farmers able to adapt to, and even thrive in, such an uncertain environment?

Over the past 10,000 years, small-scale subsistence farmers have relied on a suite of strategies to maintain stable food supplies given uncertain rainfall. These strategies includes practices like crop diversification, storage, mobility, and exchange [@Halstead1989]. 
Crop diversification in particular is an excellent example of a widespread and effective risk management strategy that is well suited to Mediterranean agroecosystems. In the Mediterranean, land-use strategies involving a diversified portfolio of wheat and barley have been employed by even the earliest sedentary farmers, and continue to be used to this day [@GOULD1963a,Slafer1999,Abbo2009a,abbo2010,weiss zohary 2011,Marston2011190]. Relying on a mix of food types with different climatic tolerances is an efficient way to maintain a robust food supply [@helmers2001separating,Anderies2006]. Wheat is high yielding but drought sensitive, while barley is lower yielding but drought tolerant. Planting a mix of high yield, high risk and low yield, low risk crops, either in the same plot or in a combination of plots, is an effective means of diversifying the annual supply of staple food crops [@paul et al 2019]. By dynamically adjusting the ratio of wheat to barley in their fields, farmers can adapt to a variety local climate conditions with different drought risks.

Risk-managing strategies like crop diversification require farmers to make specific resource allocation decisions in response to specific environmental risks, so are sensitive to variability in both the spatiotemporal patterns of risk and the ability of individual decision-makers to perceive and act on those patterns. Here, I focus on two main questions:

1. How likely were droughts to occur each year in the eastern Mediterranean, and how did these risks change over the Holocene?

2. How might Neolithic farmers have perceived these changing risks, and what were the consequences for Neolithic farmers' collective ability to manage them?

To address these questions, I first use results from a long-term paleoclimate simulation to estimate the changing risk of agricultural droughts in the eastern Mediterranean over a 4,000 year period in the early to middle Holocene. Then, I use a simulated population of Bayesian "belief-based" agents to explore how well individual farmers would have been able to perceive these long-term changes in drought risks given their finite life experiences and limited capacity to process information. This computational approach allows for a more nuanced understanding of the vulnerability of risk-management strategies to unpredictable climatic variability.

# Decision-making in a game against nature {#sec:1}

The basic decision-making problem facing a farmer seeking to diversify their crops can be thought of as a "game against nature" [@LuceRaiffa1989, Milnor1952, Agrawal1968, cassidy1971, gould1963]. In the context of decision theory, the "game" is the farmer's decision of which crops to plant and in what proportions, given uncertainty in the weather (or the "state of nature") in a given year. Assume that a farmers are working with a simplified representation of reality and intuitively solve an easier problem when faced with a complex real-world situation [@Simon1952]. That is, rather than a continuum of possible states of nature, only care about two categories -- years when its too dry to plant wheat and years when it is not.

## The payoff matrix

This simplified decision problem can take the form of a payoff matrix in which the rows represent the moves of the farmer (wheat or barley) and the columns are the moves of nature (dry or normal) (Table 1). The matrix is populated with realistic estimates of potential crop yields in each scenario -- using data from isotopic analysis of grain residues at Neolithic sites [@Slafer1999] -- but the absolute yields are less important for the decision-making problem then the relative sums of each row and column. What strategies might a farmer use to "win" this game and maximize their yields?

\begin{table}
\centering
\caption{Estimates of yield volume (t/ha) for prehistoric wheat and barley varieties derived from (Slafer et al. 1999). The absolute values here are less important for decision-making than the relative values across each row and column.}
\begin{tabular}{|l|l|l|}
\hline
 & Dry Year & Normal Year \\ \hline
Barley Yield & 0.93 & 1.18 \\ \hline
Wheat Yield & 0 & 1.60 \\ \hline
\end{tabular}
\end{table}

```{r}
wheat_dry <- 0
wheat_normal <- 1.6

barley_dry <- 0.93
barley_normal <- 1.18
```


There are several decision criteria a farmer might use in this situation [@Agrawal1968]. A risk neutral farmer seek only to maximize yields in a normal year by planting wheat and hoping for the best, as wheat is the highest yielding crop overall. But this strategy risks starvation in drought years. 

Instead it is often rational to assume "nature's" moves are decided by sentient being bent on one's ruin, and to play strategically based on that assumption [@Gould 1963, Beckenkamp 2008]. In the particular form of the wheat-barley game presented in Table 1, a risk sensitive farmer would assume that droughts are inevitable and plant barley to guarantee a minimum acceptable harvest even in the worst case scenario. This cautious strategy has some benefits -- particularly in situations of complete uncertainty -- but farmers miss out on high yields they would have received from planting wheat if a drought ultimately does not occur.

## Maximizing subjective expected yields

Playing this "game" over many years allows farmers to learn how probable each state of nature is to occur and to adjust their choices accordingly. This strategy is known as playing a game of "fictitious play" against nature. If the empirical frequency distribution of wet and dry years is known, the farmer can multiply the crop yields in Table 1 by the probability of each state of nature occurring, and plant the crop with the highest *expected* yield. If the probability of a dry year is denoted $\theta$, then the expected barley yield is $\theta \times 0.93 + (1 - \theta) \times 1.18$ and the expected wheat yield is $\theta \times 0 + (1 - \theta) \times 1.60$. Barley is favored if $\theta$ is low and droughts are more likely, wheat is favored if $\theta$ high, and the value of $\theta$ at which expected barley and wheat yields are the same is known as the point of indifference (Figure \@ref(fig:yields)). If a farmer is unsure whether $\theta$ is above or below the point of indifference, they can plant a mix of crops that maximizes expected yields given their uncertainty in $\theta$. Thus, the exact risk of a drought occurring in any given year, and farmers' perceptions of that risk, have major implications for the entire decision-making process

```{r yields, fig.cap = 'Expected wheat and barley yields under increasing drought risk. The point of indifference is highlighted, at which point planting either wheat or barley results in the same expected yield.'}
expected_yield_wheat <- function(risk) {
  risk * wheat_dry + (1 - risk) * wheat_normal
}

expected_yield_barley <- function(risk) {
  risk * barley_dry + (1 - risk) * barley_normal
}

expected_yield <- function(risk) {
  expected_yield_wheat(risk) + expected_yield_barley(risk)
}

indiff <- tibble(risk = (barley_normal - wheat_normal) / (wheat_dry - wheat_normal - barley_dry + barley_normal),
                 yield = risk * wheat_dry + (1 - risk) * wheat_normal)
indiff_label <- paste0('(', round(indiff$risk, 2), ', ', round(indiff$yield, 2), ')')

tibble(risk = seq(0, 1, .1),
      Barley = expected_yield_barley(risk),
      Wheat = expected_yield_wheat(risk)) %>%
  gather(type, yield, Barley:Wheat) %>%
  ggplot(aes(risk, yield)) +
  geom_hline(yintercept = indiff$yield, linetype = 2, alpha = .6)+
  geom_vline(xintercept = indiff$risk, linetype = 2, alpha = .6) +
  geom_line(aes(color = type), size = 1.2) +
  geom_point(data = indiff, color = 'black', size = 3) +
  geom_text(data = indiff, label = indiff_label, nudge_x = 0.1, nudge_y = 0.1) +
  theme_classic() +
  scale_color_manual(values = c('#e66101', '#5e3c99'), name = '') +
  labs(x = expression('Drought probability (' * theta * ')'), y = 'Expected yield (t/ha)')
```


# Early to mid-Holocene drought risks {#sec:2}

In order to estimate drought risks in the past, present-day weather observations alone are insufficient. Precipitation varies not only from year-to-year, but also on centennial to millennial-scale time scales that are unresolved in the contemporary observational record. Climate dynamics are non-linear, non-stationary, and non-ergodic, which means sudden, unpredictable variability is the norm rather than the exception. 

Estimates of past climate variability derived from paleoclimate simulations provides a richer representation of not only the first order statistics of the climate system (e.g. the mean and variance of precipitation) but also the higher order patterns such as the serial persistence of wet and dry years. This presents a much more realistic picture of the inherent year-to-year uncertainty in the climate system, and presents a realistic challenge to simple risk-managing strategies that assume climatic risks are fixed.

## Paleoclimate simulation

Estimates of changing Holocene precipitation variability were derived from the TraCE-21ka paleoclimate simulation [@He2011]. TraCE-21ka is a state-of-the-art simulation that uses a coupled atmosphere-ocean general circulation model to recreate the transient response of the global climate system to changes in the Earth's orbit and greenhouse gas concentrations from the Last Glacial Maximum to the present. The simulation generates physically consistent spatiotemporal climate dynamics, driven by current best estimates of external climate drivers (e.g. Earth's orbit, greenhouse gasses, glacial meltwater flux). The model simulates these dynamics on a six hourly timescale, and model outputs are archived at a monthly resolution. For this analysis, monthly TraCE-21ka precipitation outputs were extracted from the 3.75° grid cell covering Central Anatolia. This location was selected to capture climate variability typical for major Neolithic settlements in the region, such as Çatalhöyük and Aşıklı Höyük, and for the eastern Mediterranean more broadly. 

```{r}
konya <- matrix(c(32.5, 37.9), nrow = 1) # point at which to sample TraCE
```


```{r}
# convective precipitation
precc <- map(
  list.files('../Data/PRECC', full.names = TRUE)[-12],
  ~ brick(.) %>%
    raster::extract(konya, df = TRUE) %>%
    select(-ID) %>%
    gather(time, precc)
) %>%
  bind_rows()

# large-scale precipitation
precl <- map(
  list.files('../Data/PRECL', full.names = TRUE)[-12],
  ~ brick(.) %>%
    raster::extract(konya, df = TRUE) %>%
    select(-ID) %>%
    gather(time, precl)
) %>%
  bind_rows()
```

## Estimating drought risks

Using the climate model output, I divided each model year into dry years and normal years. A dry year was any year where less than 300mm of rain fell during the wet season (October-May), the threshold below which wheat crops will generally fail [@Wilkinson1997], and a normal year was defined as any year above this threshold. Given the modeled patterns of normal and dry years, the "objective" climatic drought risk $\hat\theta$ for any particular year was defined as the proportion of the previous 50 years that were dry years:
\begin{equation}
    \hat\theta = \frac{\sum_{n=t-1}^{t-50} P_n < 300}{50},
\end{equation} 
where $P_n$ is the growing season precipitation accumulation in millimeters for year $n$.

```{r}
sim_past <- left_join(precc, precl, by = 'time') %>%
  mutate(
    rainfall = (precc + precl) * 2.628e+9, # unit conversion
    year = rep(-10200:-5001, each = 12),
    # hardcode dates instead of using ncdf time because of date shift with averaging period
    month = rep(1:12, times = 5200)
  ) %>%
  select(-time,-precl,-precc) %>%
  mutate(water_year = if_else(month %in% 10:12, year + 1L, year)) %>%
  filter(!(month %in% c(6:9))) %>%
  group_by(water_year) %>%
  add_tally() %>%
  filter(n == 8) %>%
  summarise(precip = sum(rainfall)) %>%
  mutate(drought = precip < 300) %>%
  filter(between(water_year, -9500, -5500)) %>%
  mutate(time_step = ceiling(water_year / 50),
         year = time_step * 50) %>%
  group_by(year) %>%
  summarise(risk = sum(drought) / 50) %>%
  filter(year != min(year)) 
```

The simulated risks of crop failure due to drought ranged between 10\% and 46\% during the period from 9.5ka to 5.5ka, with a median risk of 24\% (Figure \@ref(fig:risk)). On average, a Neolithic farmer in Central Anatolia could expect their wheat crops to fail two or three times a decade, punctuated by even drier periods in which wheat crops could be expected to fail roughly every other year. The simulation also reveals a long-term trend of decreasing drought risks, in particular with higher drought risk in the early Holocene giving way to lower drought risk in the middle Holocene.

```{r risk, fig.asp = 0.3333, fig.cap = 'Annual risk of wheat crop failure due to drought aggregated by fifty-year period. The dashed line indicates the level of risk beyond which one would plant barley over wheat to maximize subjective expected yields (after Figure 1), given the payoffs defined in Table 1.'}
sim_past %>%
  ggplot(aes(year, risk, fill = risk, color = risk)) +
  geom_hline(yintercept = indiff$risk, color = 'black', linetype = 2, size = 1) +
  geom_col(width = 38)  +
  scale_fill_distiller(palette = 'PuOr') +
  scale_color_distiller(palette = 'PuOr')+
  theme_minimal() +
  labs(x = 'Years BP', y = 'Drought risk') + theme(legend.position = "none")
```

The TraCE-21ka simulation confirms that drought risk in the eastern Mediterranean was non-stationary and, in fact, quite volatile during periods of climatic disruption in the early Holocene. This volatility would have had severe consequences for early farming communities whose risk-managing practices depended so heavily on accurately perceived local climatic risks.


# Modeling risk perception {#sec:3}

In order to properly manage drought risk, a farmer must first be able to perceive that risk. Yet, a farmer's perception of risk reflects more than just the objective, empirical risk observable in the world around them [@Tucker2013]. Individual risk perception is inherently subjective -- influenced by a person's past experience of dry and wet years as filtered through memory -- and can reflect varying levels of uncertainty. Likewise, the distribution of individuals' perceived risks within a population influences the collective perception of drought risks and the potential aggregate societal-level response to those risks [@Moussaid2013]. But how best to model risk perception at the individual level? 

## Prior beliefs and Bayesian agents

The human brain does not record every bit of perceived information in memory, rather it stores a "compact encoding" of that information which it uses for future decision-making. Integrating the tools of agent-based modeling and Bayesian probability provide an elegant means of representing this process. A Bayesian "belief-based" agent is an one whose subjective beliefs can be represented as a probability distribution over possible states of nature [@Kahvalti et al 2019 and others????]. This approach has a clear computational efficiency -- for both modelers and decision-makers -- and even if real-world decision makers are not Bayesians in a literal sense, the basic algorithmic problem faced by the brain, and the solutions it has evolved, reflect the same constraints on information processing in the minds of decision-makers [@Sanborn and Chater 2016].

We can examine the dynamics of risk perception using a population of Bayesian agents that develop beliefs about the risk of drought in their environment through their personal experience of the weather, and these perceptions impact their decision-making by altering their subjective expected crop yields from planting different crop mixes. Here, the probability of a drought occurring in any given year is treated as a coin flip (i.e. a draw from Bernoulli distribution) with parameter $\theta$ representing the drought probability. The beta distribution is a natural choice for representing knowledge about probabilities because it is constrained to fall between 0 and 1. Hence, an individual agent's prior belief about the plausivle value of $\theta$ can be represented as
\begin{equation}
  \theta \sim \textrm{Beta}(\alpha, \,\beta),
\end{equation}
a beta distribution with the parameters $\alpha$ and $\beta$ corresponding to the number of dry and wet years previously experienced by that agent. Varying these two parameters thus allows for the representation of a variety of different personal experiences of drought risk. For example, if an agent recalls having lived through 5 dry years and 25 normal years, their prior belief about the chance of a drought occurring in the following year would be represented as a Beta(5, 25) distribution with mean value 0.2 equivalent to the empirical drought risk ($\hat\theta$) for that period.

Using probabilities to represent agents' beliefs also allows for estimation of the *uncertainty* in those beliefs (Figure \@ref(fig:prior-prob)). A simple Bayesian agent becomes more certain in their beliefs with age. For example, an agent who experienced 5 wet and 10 normal years and one who experienced 25 wet and 50 normal years would both agree that, on average, droughts occur 50\% of the time. Yet the latter agent would be much more certain in this belief because it is drawn from a larger range of experience (i.e. a larger sample size). We can thus represent the exact information content of each individual agent's subjective experience of droughts using the diffusion of this prior belief. How, then, should an agent update its beliefs in light of new experience? 

```{r prior-prob, fig.cap = "Development of an individual's perceived drought risk with time, assuming a fixed drought risk of 0.5. Beliefs are represented as beta distributions, and the increased certainty with age reflects the varying effective sample size of the beta prior."}
prior <- function(m, n) {
  domain <- seq(0,1,0.005)
  val <- dbeta(domain, n * m, n * (1 - m))
  tibble('x' = domain, 'y' = val)
}

tibble(Age = seq(5, 50, 5),
       risk = 0.5) %>%
  mutate(belief = map2(risk, Age, ~prior(.x, .y))) %>%
  unnest(cols = c(belief)) %>%
  ggplot(aes(x, y)) +
  geom_line(aes(group = Age, color = Age), size = 1.2) +
  scale_color_distiller(palette = 'PuOr', guide = 'legend') +
  labs(x = expression('Perceived drought risk (' * theta * ')'), y = 'Density') +
  theme_classic()
```


## Bayesian updating and the weight of past experience

As a Bayesian agent must be able to update its beliefs as it moves through time and observes each successive year's weather. It does does by comparing the information in this year's observation with the cumulative weight of their past experience. The agent combines its prior beliefs about drought risk with the likelihood of having observing a drought in the current year in order to generate a posterior distribution representing its updated beliefs about the world. 

Crucially, the strength of one's prior beliefs determines how much weight is given to new information (Figure \@ref(fig:posterior)). For example, assume two agents -- one aged 15 and the other aged 50 -- who have only ever experienced a normal climate where droughts happen on average two out of every ten years. The mean value of $\theta$ for both agents would thus be 20\%, but the degree of certainty varies because the older agent bases its inference on many more years of experience than the younger agent. Now, assume the climate suddenly changes such that the drought risk is doubled to 40\% for the next 25 years -- not an uncommon occurrence in the simulation of early to mid-Holocene climate. Because the prior beliefs of the agents were so different, their subjective beliefs after the drought are also different *even though both experienced the same climate*.

For young agents with weak priors, the information of each new year can thus strongly influence their beliefs. But older agents -- having more experience and stronger priors -- will be less likely to update their beliefs when comparing the information from a single year's weather with previous decades' worth of accumulated experience. Although neither agent may perceive the "true" climatic drought risk exactly, they nevertheless reflect perfectly rational beliefs about the world. Both agents have perfectly rational beliefs and differ only in their prior subjective beliefs - their relative conservatism or flexibility are not biases but rather varying perspectives on an inherently uncertain world.

As was the case in the game of "fictitious play" discussed in Section \@ref(sec:1), a degree of conservatism is warranted when the environment is stable and risks do not vary. But when the environment is volatile the ability to change one's mind is crucial. Being too inflexible in one's priors can lead being too optimistic when things really have changed for the worse, or too conservative when conditions ultimately improve.

```{r posterior, fig.asp = 0.5, fig.cap = "Change in perceived drought probability in an older (50) and younger (15) agent before and after a 25-year dry period."}
prior2 <- function(a, b) {
  domain <- seq(0,1,0.005)
  val <- dbeta(domain, a, b)
  tibble('x' = domain, 'y' = val)
}

tibble(alpha = c(15 * 0.2, 50 * 0.2, 15 * 0.2 + 25 * 0.4, 50 * 0.2 + 25 * 0.4),
       beta = c(15 * 0.8, 50 * 0.8, 15 * 0.8 + 25 * 0.6, 50 * 0.8 + 25 * 0.6),
       time = factor(c('prior', 'prior', 'posterior', 'posterior'), levels = c('prior', 'posterior')),
       age = factor(c('15-year-old agent', '50-year-old agent', '15-year-old agent', '50-year-old agent'), levels = c('15-year-old agent', '50-year-old agent'))) %>%
  mutate(belief = map2(alpha, beta, ~prior2(.x, .y))) %>%
  unnest(cols = c(belief)) %>%
  ggplot(aes(x, y)) +
  geom_line(aes(group = time, color = time), size = 1.2, alpha = .9) +
scale_color_manual(values = c('#5e3c99', '#e66101'), name = '') +
    facet_wrap(~age, strip.position = 'bottom') +
    theme_classic() +
  theme(strip.background = element_blank(),
        legend.position = c(.43, .5),
        strip.placement = "outside") +
  labs(x = expression('Perceived drought risk (' * theta * ')'), y = 'Density')
```

# Risk management and the dynamics of risk perception {#sec:4}

The previous example established some basic intuitions for how agents with varying subjective beliefs can perceive risk differently. But it represents an idealized situation where agents update their beliefs retrospectively after a many-year dry period. Farmers, on the other hand, must update their planting decisions each year and continuously monitor the weather around them. The transient, year-to-year changes in perceived risks can thus have major consequences for how a population responds *during* a dry period. How do Bayesian learners perform in such an uncertain, unpredictable time? 

To explore these dynamics further we can simulate random sequences of wet and dry years and see how a population of Bayesian agents responds to this sequence in time. A 75-year period of low (20\%) drought risks is punctuated by an abrupt 25 years dry period during which drought risk doubles. Here, observations are made about the world sequentially, and the agents must continuously update their beliefs. As in the previous section, an agent's prior belief about drought risk is updated in light of new experience to generate a posterior perception of risk. Now, however, this update occurs every year and thus only a year's worth of new information is incorporated into the agent's beliefs each time step. This learning process is iterative, as an agent's posterior distribution in one year becomes their prior following year and the updating process repeats itself. Formally, this iterative process is known as "online" learning from Bernoulli observations, where "online" refers to the sequential, year-to-year updating [@Bissiri2010]. 

```{r}
agents <- tibble(id = 1:150, 
                 alpha = 1.5,
                 beta = 1.5,
                 risk = alpha / (alpha + beta),
                 crop = 'barley')

learn <- function(agents, drought) {
  if (drought == 'TRUE') wheat_yield <- wheat_dry; barley_yield <- barley_dry
  if (drought == 'FALSE') wheat_yield <- wheat_normal; barley_yield <- barley_normal

  agents %>%
    # farmer's turn to decide what to plant
      mutate(yield_exp = expected_yield(risk),
         barley_exp = expected_yield_barley(risk),
         wheat_exp = expected_yield_wheat(risk),
         crop = case_when(barley_exp > wheat_exp ~ 'barley',
                              barley_exp < wheat_exp ~ 'wheat',
                              barley_exp == wheat_exp ~ 'either'),
         prediction = map2(alpha, beta, ~rbeta(100, .x, .y)), # sample 100 as if agent is thinking in percentages
         wheat_prop = map_dbl(prediction, ~sum(. < indiff$risk)) / 100) %>%
      select(-prediction) %>%
  # "nature's" turn to decide realized yields
    mutate(alpha = drought + alpha,
           beta = beta + 1 - drought,
           risk = map2_dbl(alpha, beta, ~rbeta(1, .x, .y)))
}
```

```{r}
set.seed(11111)
droughts <- c(runif(25) < 0.2, runif(25) < 0.4, runif(25) < 0.2)

run_sim <- function(droughts) {
  accumulate(droughts, ~learn(.x, .y), .init = agents) %>% 
    bind_rows(.id = 'time') %>%
    mutate(time = as.numeric(time)) %>%
    filter(time > 1)
}

sim1 <- run_sim(droughts)
```

The results of this simulation reveal the importance of the subjective experiences of individual decision makers on the population-level perception of risk (Figure \@ref(fig:dynamics)a). In this learning environment, isolating signal from noise becomes critical for accurately perceiving evolving drought risks. All agents begin the simulation with diffuse subjective beliefs about drought risk, but as they begin to learn the collective subjective beliefs approaches the objective risk level. The agents are slow to update their beliefs during the 25-year dry period because drought years, while increasingly frequent, are still few enough not to outweigh the agents prior beliefs. Some agents may perceive gradual changes, but the population as a whole does not perceive the change in climate until more than a decade after it has begun. 

The agents are even slower to realize when the dry period is over. Indeed, the dry period made a strong enough imprint on the population's collective memory that the they perceive droughts to be much more probable than they actually are for decades after conditions have ameliorated once and for all. These biased perceptions have consequences for collective ability of the population to manage risk, because uncertainty in whether drought risks are above or below the indifference point informing the mix of crops to plant (Figure \@ref(fig:dynamics)b). Once again, the skewed perceptions of increased drought risks last long after the dry period ends, reflected in a much higher ratio of barley to wheat -- a more cautious crop mix -- than is rational given the objective risk of drought in the environment.


```{r dynamics, fig.asp = 1, fig.cap='A) Perceived drought risks in a population of Bayesian agents before and after a drought (grey band). The dashed red line represents the level of risk at which an agent is indifferent between planting wheat and barley. B) Crop mix over time, calculated based on the degree of dispersion above and below the indifference level in A.'}
a <- ggplot(sim1) +
  geom_rect(aes(xmin = 25, xmax = 50, ymin = -Inf, ymax = Inf), fill = 'lightgray', alpha = .2) +
  geom_point(aes(time, risk), alpha = .1) +
  geom_hline(yintercept = indiff$risk, color = 'red', linetype = 2) +
  theme_classic() +
  labs(x = 'Year', y = 'Perceived drought risk')

b <- sim1 %>%
  group_by(time, crop) %>%
  tally() %>%
ggplot(aes(time, n, fill = crop, color = crop)) +
  geom_bar(width = 1, stat = 'identity', position = 'fill') +
    scale_fill_manual(values = c('#f1a340', '#998ec3'), name = '') + 
    scale_color_manual(values = c('#f1a340', '#998ec3'), name = '') + 
    labs(x = 'Year', y = 'Wheat proportion') +
  theme_classic()

a / b + plot_annotation(tag_levels = 'A')
```

# Conclusion

In this chapter, I explored the consequences of individual heterogeneity in risk perception on the risk-management practices of a simulated Neolithic farming community. I used a long-term paleoclimate simulation over the eastern Mediterranean to estimate the changing risks of agricultural drought over a 4,000 year time period spanning the early to mid-Holocene. Over this time, wheat crops would have been expected to fail from drought between once every ten years to nearly once every two years. Changes of such magnitude would have severely impacted Neolithic agroecosystems in the long run, but would have been difficult for any individual farmer to perceive in the short run. 

To explore these dynamics, I simulated a population of "belief-based" Bayesian agents who use their subjective perception of annual drought risks to decide what mix of crops will best manage those risks. During periods of climatic stability, allowing past experiences to influence decision making helps farmers minimize the impacts of \emph{predictable} drought. But past experiences are less informative during periods of rapid climate change, and even farmers who manage risk “optimally” in light of their prior beliefs can experience food shortfalls. Cognitive diversity and life experience can be as or more important than the exact mix of crops planted for a population's long-run survival under extreme uncertainty.

These dynamics have implications for understanding risk management and food production in the Neolithic. Two points arise that this model helps clarify our understanding of the earliest farming communities in the Mediterranean and can inform future simulation work:

1. **Risk perception is hard.** The climate system is inherently chaotic. Annual forecasts are fundamentally uncertain, even in the era of modern supercomputers and numerical weather prediction. For prehistoric farmers, this uncertainty would have been a existential challenge. With the end of the Last Glacial Maximum and the advent of the Holocene, precipitation became increasingly volatile on multiple time scales. This uncertainty in the objective drought risk is only compounded by uncertainty in individual farmers' subjective perception of drought risk. Any individual would have experienced only a brief snapshot of this complex period. The rhythm of a single human lifespan is out of sync with the centennial to millennial scale oscillations in the climate system, so even the predictive value of one's own experience is itself unpredictable. This fundamental uncertainty would have influenced far more than the choice of which type of crops to plant -- and would have pervaded all kinds of decision-making under risk.

2. **Individual risk perception has consequences for collective risk management.** Individuals of different ages may perceive the same dry period differently depending on their prior life experience. Younger individuals are more likely to perceive a run of dry years as a trend, rather than a temporary deviation from the norm, and older individuals  are likely to do the opposite. By extension, the age structure of a population will influence how quickly it is able to perceive and adapt to a changing climate. For example, a young, fast growing population will have a different collective memory of a past drought event then an older population. Likewise, baby booms and busts associated with famines, or any mortality crisis that afflicts specific age classes like warfare or epidemics, will alter the time horizon of that population's collective memory. Individual heterogeneity in risk perceptions can thus play a key role in broader social responses to climatic risks.

Relating collective knowledge to individual cognition is essential for understanding human behavior in complex social-ecological systems [@Beratan2007]. Although social learning and cumulative cultural evolution have not been a focus of this paper (see [@Boyd and Richerson 1998, 2001]), these findings provide insight into the individual learning dynamics that underlay those broader social processes. This chapter has focused primarily on the physical and cognitive dimensions of risk and risk perception. The social context of risk and risk perception can be equally consequential [@Rogers1997]. The balance of individual learning with social transmission determines the collective perception of risks and its impact on collective memory [@Moussaid2013, candia2019]. Our finite lifespans ultimately keep the skill of individual learning low over the long term -- cumulative cultural evolution is required. 

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
\setlength{\parskip}{8pt}


# References
\noindent
